---
title: "Results_paper1"
author: "Amieroh Abrahams"
date: "07 April 2019"
output: html_document
---

This scripts comprise of the analyses needed for the first section of my masters project. 

# Loading libraries
First I need to find, install and load various packages. These packages will be available on CRAN and can be accessed and installed in the usual way.
 
```{r prelim_opts, echo=FALSE}
knitr::opts_chunk$set(
  comment = "R>",
  warning = FALSE,
  message = FALSE 
)

library(tidyverse)
library(plyr)
library(lubridate)
library(ggpubr)
library(zoo)
library(lubridate)
library(FNN)
library(forecast)
library(astrochron)
library(WaveletComp)
library(data.table)
library(heatwaveR)
library(viridis)
library(ggrepel)
library(plyr)
library(maptools)
library(sp)
library(geosphere)
library(PBSmapping)
library(scales)
library(grid)
library(gridExtra)
library(circular)
library(fossil)
library(mapproj)
library(ncdf4)
library(reshape2)
library(plyr) # Never load plyr when also loading the tidyverse. It causes a lot of conflicts.
library(stringr)
library(doMC); doMC::registerDoMC(cores = 4)
library(fasttime)
library(xtable)
library(ggpubr)

# library(devtools)
# install_github("marchtaylor/sinkr")

## Functions
source("functions/earthdist.R")
source("functions/wind.rose.R")
source("functions/theme.R")
source("functions/scale.bar.func.R")
```

## Load site list SACTN data

Now to get to the data. The first step involves the loading of the site list. The statistical properties of the seawater temperature representing the South African coastline, such as the mean, minimum and maximum temperatures. These values vary among coastal sections due to the influence of the cold Benguala and warm Agulhas currents. Here we will only focus on the temperature data found along the west coast (wc) (i.e. sites influenced by the Benguela current, EBUS). The SACTN dataset comprise of 129 *in situ* coastal seawater temperatures derived from daily measurements over up to 40 years. The SACTN temperature dataset was compiled by measuring coastal temperatures at 129 sites along the coast of South Africa, daily from 1972 until 2017. 

```{r load_files1, include=TRUE}
load("Data_P1/site_list_v4.2.RData")
load("Data_P1/SACTN_daily_v4.2.RData")
```

## Selecting the sites and creating new *in situ* datasets

Now we select only the sites occuring along the west coast. The purpose of this is to assess whether or not the intensity of upwelling varies at a range of distances from the coastline. The data used here is obtained from different satellites and thus represent different resolutions. I then find an overlapping time series for each of the sites along the west coast. The length of time series for each of the sites is greater than 10 years. The sites along the west coast vary between upwelling centres and further away from the upwelling centres. As a result it is hypothesised that sites located within the upwelling centre may resemble a longer more intense upwelling event when compared to sites located further away from the upwelling centre. For this analyses a long term time series of 30years is not required and so our time series starts in 1992 - 2015.

```{r}
site_list_sub <- site_list %>%
  filter(coast == "wc") %>%
  filter(length > 3650) 
site_list_sub <- site_list_sub[c(-2, -3, -5, -6, -7,-9, -12, -13, -14),] # Here I keep all the sites with temperature obtained up to 2017
# save(site_list_sub, file = "Data_P1/site_list_sub.Rdata")

SACTN_US <- SACTN_daily_v4.2 %>%
  left_join(site_list[,c(4,13)], by = "index") %>%
  filter(index %in% site_list_sub$index) %>%
  separate(index, into = c("site", "src"), sep = "/", remove = FALSE) %>%
  dplyr::rename(insitu_temp = temp)

# The next step is to identify the period where all sites within this dataset overlap
SACTN_overlap <- SACTN_US %>% 
  filter(year(date) %in% seq(1992, 2015)) %>% # The length of the time may vary depending on the question
  drop_na() # Removing NA values within the dataset
# save(SACTN_overlap, file = "Data_P1/SACTN_overlap.RData")

# Visualising the data
temp_plot <- function(df){
  plot <- ggplot(data = df, aes(x = date, y = insitu_temp, colour = site)) +
    geom_line(aes(group = site)) +
    labs(x = "", y = "Temperature (°C)") +
    theme(axis.text.x = element_text(angle = 45)) +
    theme(legend.position = "top")
}

SACTN_plot <- temp_plot(df = SACTN_overlap)
```

# Remotely sensed SST datasets
Matching the satellite sea surface temperature data point to the in situ temperature collected data points. The MUR data is not present within the data_P1 folder and so needs to be loaded into the data folder.

## MUR dataset

```{r}
MUR_Lamberts_Bay <- read_csv("Data_P1/MUR_nearest5pixels/MUR_Lamberts Bay_SST_timeseries_5nearest.csv")
MUR_Port_Nolloth <- read_csv("Data_P1/MUR_nearest5pixels/MUR_Port Nolloth_SST_timeseries_5nearest.csv")
MUR_Saldanha_Bay <- read_csv("Data_P1/MUR_nearest5pixels/MUR_Saldanha Bay_SST_timeseries_5nearest.csv")
MUR_Yzerfontein <- read_csv("Data_P1/MUR_nearest5pixels/MUR_Yzerfontein_SST_timeseries_5nearest.csv")
MUR_Kommetjie <- read_csv("Data_P1/MUR_nearest5pixels/MUR_Kommetjie_SST_timeseries_5nearest.csv")
MUR_Sea_Point <- read_csv("Data_P1/MUR_nearest5pixels/MUR_Sea Point_SST_timeseries_5nearest.csv")

MUR_SST <- rbind(MUR_Lamberts_Bay,MUR_Yzerfontein, MUR_Port_Nolloth,MUR_Saldanha_Bay, MUR_Kommetjie, MUR_Sea_Point) %>%
  dplyr::rename(site = station)

MUR_SST$date <- (ymd(MUR_SST$date))
MUR_SST <- MUR_SST %>% 
  dplyr::rename(temp = nearest1) %>% 
  drop_na()

# save(MUR_SST, file = "Data_P1/MUR_SST.RData")
```

This function matches the remotely-sensed SST to the *in-situ* collected SST

```{r}
match_func <- function(df){
  match <- SACTN_overlap  %>%  
  left_join(df, by = c("site", "date")) %>% 
  na.trim()
  return(match)
}

# Basic visualisations
match_plot <- function(df){
  plot1 <- df %>% 
ggplot(aes(x = date, y = temp)) +
  geom_hline(aes(yintercept = mean(temp)), colour = "salmon") +
  geom_line() +
  facet_wrap(~ site, nrow = 2) +
  theme_bw()
  return(plot1)
}

temp_plot <- function(df){
  temp_plot <- df %>% 
  ggplot(aes(x = date, y = temp, colour = site)) +
    geom_line(aes(group = site)) +
    labs(x = "", y = "Temperature (°C)") +
    theme(axis.text.x = element_text(angle = 45)) +
    theme(legend.position = "top")
}

## Matching the in-situ data with the G1SST SST data
insitu_MUR <- match_func(df = MUR_SST) %>%
  drop_na()
# save(insitu_MUR, file = "Data_P1/insitu_MUR.RData")

MUR_plot <- match_plot(df = insitu_MUR)
MUR_temp <- temp_plot(df = insitu_MUR)
```

## G1SST dataset

```{r}
Lamberts_Bay <- read_csv("Data_P1/G1SST_sub/Lamberts Bay_SST_timeseries_5nearest.csv")
Port_Nolloth <- read_csv("Data_P1/G1SST_sub/Port Nolloth_SST_timeseries_5nearest.csv")
Saldanha_Bay <- read_csv("Data_P1/G1SST_sub/Saldanha Bay_SST_timeseries_5nearest.csv")
Yzerfontein <- read_csv("Data_P1/G1SST_sub/Yzerfontein_SST_timeseries_5nearest.csv")
Kommetjie_SST <- read_csv("Data_P1/G1SST_sub/Kommetjie_SST_timeseries_5nearest.csv")
Sea_Point_SST<- read_csv("Data_P1/G1SST_sub/Sea Point_SST_timeseries_5nearest.csv")

G1SSTsub_SST <- rbind(Lamberts_Bay, Port_Nolloth, Saldanha_Bay, Yzerfontein, Kommetjie_SST, Sea_Point_SST) %>%
  dplyr::rename(site = station)

G1SSTsub_SST$date <- (ymd(G1SSTsub_SST$date))
# save(G1SSTsub_SST, file = "Data_P1/G1SSTsub_SST.RData")

G1SSTsub_SST <- G1SSTsub_SST %>% 
  drop_na() %>% 
  dplyr::rename(temp = nearest1)

## Matching the Insitu data with the G1SST SST data
insitu_G1SST <- match_func(df = G1SSTsub_SST) 
# save(insitu_G1SST, file = "Data_P1/insitu_G1SST.RData")

G1SST_plot <- match_plot(df = insitu_G1SST )
G1SST_temp<- temp_plot(df = insitu_G1SST)
```

## K10 dataset

```{r}
Lamberts_Bay <- read_csv("Data_P1/K10/K10_Lamberts Bay_SST_timeseries_5nearest.csv")
Port_Nolloth <- read_csv("Data_P1/K10/K10_Port Nolloth_SST_timeseries_5nearest.csv")
Saldanha_Bay <- read_csv("Data_P1/K10/K10_Saldanha Bay_SST_timeseries_5nearest.csv")
Yzerfontein <- read_csv("Data_P1/K10/K10_Yzerfontein_SST_timeseries_5nearest.csv")
Kommetjie <- read_csv("Data_P1/K10/K10_Kommetjie_SST_timeseries_5nearest.csv")
Sea_Point <- read_csv("Data_P1/K10/K10_Sea Point_SST_timeseries_5nearest.csv")

K10_SST <- rbind(Lamberts_Bay, Yzerfontein, Port_Nolloth, Saldanha_Bay, Kommetjie, Sea_Point) %>%
  dplyr::rename(site = station)
K10_SST$date <- (ymd(K10_SST$date))
save(K10_SST, file = "Data_P1/K10_SST.RData")

K10_SST <- K10_SST %>% 
  drop_na()
K10_SST <- K10_SST %>% 
  dplyr::rename(temp = nearest1)

## Matching the Insitu data with the K10 SST data
insitu_K10 <- match_func(df = K10_SST) 
# save(insitu_K10, file = "Data_P1/insitu_K10.RData")

K10_plot <- match_plot(df = insitu_K10)
k10_temp <- temp_plot(df = insitu_K10)
```

## OISST dataset

```{r}
OISSTDir <- "~/Documents/Masters_2019/Data_SST"
OISST <- fread(paste0(OISSTDir, "/csvavhrr-only-v2-19810901-20180630.csv"),
            col.names = c("lon", "lat", "temp", "date"))

# Visualise the data
# To explore the data I visualise the min temperatures along the South african coastline.

OISST %>%
  filter(date == min(date)) %>%
  ggplot(aes(x = lon, y = lat)) +
  geom_raster(aes(fill = temp))
```

## The nearest SST pixels
Now we apply the FNN (Fast Nearest Neighbor) package to determine the nearesr SST pixel to the insitu collected sites. 

```{r}

load("Data_P1/site_list_sub.Rdata") # Loading the SACTN_overlap dataset which allows me to match it to the OISST data 

unique_pixel <- OISST %>%
  select(lon, lat) %>%
  unique()

# Select nearest 1 pixels (k = 1)
# Here I use knnx to find the closes 1 pixels to the insitu sites
match_index <- knnx.index(data = as.matrix(unique_pixel[,1:2]),
                      query = as.matrix(site_list_sub[,5:6]), k = 1)

pixel_match <- unique_pixel[match_index,] %>%
  unite(col = combi, lon, lat, sep = "/", remove = F) %>%
  mutate(site = site_list_sub$site)

# Subsetting the OISST data to match the upwelling sites within the in situ collected temperature data
OISST_match <- OISST %>%
  unite(col = combi, lon, lat, sep = "/", remove = F) %>%
  filter(combi %in% pixel_match$combi)
# save(OISST_match, file = "Data_P1/OISST_match.RData")

OISST_sites <- OISST_match %>%
  left_join(pixel_match, by = c("combi", "lon", "lat")) %>%
  dplyr::rename(temp_OISST =temp)

OISST_sites <- OISST_sites %>% 
  dplyr::rename(temp = temp_OISST) %>%
  dplyr::mutate(date = as.Date(date)) %>% 
  drop_na()
# save(OISST_sites, file = "Data_P1/OISST_sites.RData")

## Matching the Insitu data with the OISST SST data
insitu_OISST <- match_func(df = OISST_sites)
# save(insitu_OISST, file = "Data_P1/insitu_OISST.RData")

OISST_plot <- match_plot(df = insitu_OISST)
OISST_temp <- temp_plot(df = insitu_OISST)
```

## Wavelets
Wavelet anlyses showing the temperature variation between sites along the west coast for the years 2010 - 2014. Working with remotely-sensed SST and *in-situ* collected coastal seawater temperature, in the analyses below I aim to show how the intensity and duration of upwelling events vary between sites along the west coast of South Africa. It is important to remember that each of the datasets used within this study obtained SSTs at different resolutions. 

## Loading in the matched satellite temperature data

```{r}
load("Data_P1/SACTN_overlap.RData")
load("Data_P1/insitu_MUR.RData")
load("Data_P1/insitu_OISST.RData")
load("Data_P1/insitu_G1SST.RData")
load("Data_P1/insitu_K10.RData")
```

# Time series

Creating a time series from the year 2010 to 2014 for both the satellite and in situ collected SST data. This is done to provide an accurate comparison between datasets given that the different datasets have different starting and ending dates for which temperature was collected. E.g. Temperature for the MUR  only started in 2002

```{r}
filtered_years <- function(df){
  upwelling<- df %>% 
  filter(year(date) %in% seq(2010, 2014)) %>% 
  drop_na()
}

SACTN_fyears <- filtered_years(df = SACTN_overlap) 
MUR_fyears <- filtered_years(df = insitu_MUR) 
OISST_fyears <- filtered_years(df = insitu_OISST) 
G1SST_fyears <- filtered_years(df = insitu_G1SST) 
K10_fyears <- filtered_years(df = insitu_K10) 

# save(SACTN_fyears, file = "Data_P1/SACTN_fyears.RData")
# save(MUR_fyears, file = "Data_P1/MUR_fyears.RData")
# save(OISST_fyears, file = "Data_P1/OISST_fyears.RData")
# save(G1SST_fyears, file = "Data_P1/G1SST_fyears.RData")
# save(K10_fyears, file = "Data_P1/K10_fyears.RData")
```

# Wavelet analyses.
    # This creates a visualisation looking at the intensity and duration of upwelling. 
    # Here we test how the intensity and duration of an upwelling event vary between sites along the west coast of SA
    # With the hypotheses that sites closer to the upwelling centre will show a more intense, longer upwelling event

```{r}
# When doing a wavelet analyses on the SACTN dataset the "insitu_temp" column needed to be renamed to "temp" for the rest of the code to run. 
# The rest of this code is kept constant for each of the datasets (Remotely-sensed SST and In-situ seawater temperature)

SACTN_fyears <- SACTN_fyears %>%
  dplyr::rename(temp = insitu_temp)

temp.d <- function(df){
temp.d <- df %>% 
  dplyr::group_by(site, date) %>% 
  dplyr::summarise(temp = mean(temp, na.rm = T)) %>%
  dplyr::mutate(no = seq(1:n())) %>%
  dplyr::ungroup() %>% 
  dplyr::select(site, no, temp, date)
}

temp.d <- temp.d(df = SACTN_fyears) 
# temp.d <- temp.d(df = MUR_fyears) 
# temp.d <- temp.d(df = OISST_fyears)
# temp.d <- temp.d(df = G1SST_fyears) 
# temp.d <- temp.d(df = K10_fyears) 

temp.d <- temp.d %>% 
  select(site, no, temp, date)

prewhite_fun <- function(x) {
  df <- x[, 2:3]
  out <- prewhiteAR(df, order = 3, method = "mle", aic = TRUE,
             genplot = FALSE, verbose = FALSE)
  colnames(out) <- c("no", "temp")
  return(out)
  }
PN_prewhite <- as.tibble(ddply(temp.d, .(site), prewhite_fun))

ggplot(PN_prewhite, aes(x = no, y = temp)) +
  geom_hline(aes(yintercept = mean(temp)), colour = "salmon") +
  geom_line() +
  facet_wrap(~ site, nrow = 4) +
  theme_bw()

wl.fun <- function(x) {
  analyze.wavelet(x, "temp", loess.span = 0, dt = 1,
                   dj = 1/50, lowerPeriod = 2, make.pval = TRUE, n.sim = 50, 
                   method = "white.noise", verbose = FALSE)
}

PN_wave <- dlply(PN_prewhite, .(site), wl.fun, .parallel = T) # RWS: Allow parallel processing

for (i in 1:length(PN_wave)) {
  attributes(PN_wave[[i]]) <- c(attributes(PN_wave[[i]]), ref = names(PN_wave)[i])
}
# x <- PN_wave[[3]]
plot_fun <- function(x, plot_name = attributes(x)$ref) {
  png(filename = paste0("Figures",plot_name,"_wavelets.png"),
      width = 800, height = 600, units = "px", pointsize = 12, bg = "white")
  wt.image(x, siglvl = 0.05, col.contour = "black", color.key = "quantile",
           timelab = "Days", verbose = FALSE, useRaster = TRUE,
           periodlab = "Period", lwd = 1, graphics.reset = FALSE,
           main = plot_name)
  dev.off()
}
ldply(PN_wave, plot_fun, .parallel = T) # RWS: Allow parallel processing
```

#########################################################################################################################

## Load in the datasets

```{r}
load("Data_P1/SACTN_overlap.RData")
load("Data_P1/insitu_MUR.RData")
load("Data_P1/insitu_OISST.RData")
load("Data_P1/insitu_G1SST.RData")
load("Data_P1/insitu_K10.RData")
```

# Calculating a shore transect

The aim of this is to find the temperature collected at different distances from the coast (distances = 10km, 20km, 30km, 40km and 50km).

```{r}
load("Data_P1/site_list_sub.Rdata")
xtable(site_list_sub, auto = TRUE)
west <- site_list_sub
west$coast <- "west" # Chnages wc to west

load("Data_P1/africa_coast.RData")

## Downloading the bathy data from NOAA
# Download mid-res bathymetry data
# sa_lat <- c(-38, -24.5); sa_lon <- c(11.5, 35.5)
# sa_bathy <- as.xyz(getNOAA.bathy(lon1 = sa_lon[1], lon2 = sa_lon[2], lat1 = sa_lat[1], lat2 = sa_lat[2], resolution = 4))
# colnames(sa_bathy) <- c("lon", "lat", "depth")
# sa_bathy <- sa_bathy[sa_bathy$depth <= 0,]
# save(sa_bathy, file = "Data_P1/bathy/sa_bathy.RData")

# Loading in the newly downloaded bathymetry data
load("Data_P1/bathy/sa_bathy.RData")

# This function takes one site (e.g. one set of lon/lats) and calculates a shore normal transect
shore.normal.transect <- function(site, width = 2){
  # Find the site on the coastline and it's nearest neighbour points
  coords <- data.frame(lon = site$lon, lat = site$lat)
  coords2 <- knnx.index(africa_coast[,1:2], as.matrix(coords), k = 1)
  coords3 <- data.frame(site = site$site, africa_coast[c(coords2-width, coords2+width),]) 
  coords3 <- coords3[2:1,1:3]
  # Define the shore normal transect bearing
  heading <- earth.bear(coords3[1,2], coords3[1,3], coords3[2,2], coords3[2,3]) + 90
  if(heading >= 360){
    heading <- heading-360
  } else {
    heading <- heading
  }
  heading2 <- data.frame(site = site$site, lon = site$lon, lat = site$lat, heading)
  return(heading2)
}

# Creating the transects
site_transects <- data.frame()
for(i in 1:length(west$site)){
 site <- west[i,]
 site_transect <- shore.normal.transect(site, 2)
 site_transects <- rbind(site_transects, site_transect)
}

# Manually correcting Sea Point and Kommetjie
site_transects$heading[5:6] <- 290 
# save(site_transects, file = "Data_P1/site_transects.RData")
load("Data_P1/site_transects.RData")

# This function takes one site (e.g. one set of lon/lats) and calculates a shore normal transect
# It then extracts a lat/ lon point every X kilometres until reaching a specified isobath

transect.pixel <- function(site, distances){
  # Extract coordinates
  coords <- data.frame(lon = site$lon, lat = site$lat)
  # Find lon/ lats every X metres 
  pixels <- data.frame()
  # deep <- 999
  # distance_multiplier <- 1
  # while(deep > isobath){
  for(i in 1:length(distances)){
    coords2 <- as.data.frame(destPoint(p = coords, b = site$heading, d = distances[i]))
    sitesIdx <- knnx.index(sa_bathy[,1:2], as.matrix(coords2), k = 1)
    bathy2 <- sa_bathy[sitesIdx,]
    bathy2 <- bathy2[complete.cases(bathy2$depth),]
    bathy3 <- data.frame(site = site$site, lon = bathy2$lon, lat = bathy2$lat, 
                         heading = site$heading, 
                         distance = distances[i])
    pixels <- rbind(pixels, bathy3)
    coords <- coords2
  }
  if(nrow(pixels) < 1){
    pixels <- data.frame(site, depth = NA)
  }else{
    pixels <- pixels
  }
  return(pixels)
}

# Pixel points
site_pixels <- data.frame()
for(i in 1:length(west$site)){
  site <- site_transects[i,]
  site_pixel <- transect.pixel(site, c(10000, 20000, 30000, 40000, 50000)) # RWS: fixed error
  site_pixels <- rbind(site_pixels, site_pixel)
}

# save(site_pixels, file = "Data_P1/site_pixels.RData")
load("Data_P1/site_pixels.RData")

# Bounding box
  # Only one is made in order to know how large the the geom_point() squares should be made to match
bbox <- data.frame(xmin = destPoint(p = site_pixels[1,2:3], b = 270, d = 12500)[1],
                   xmax = destPoint(p = site_pixels[1,2:3], b = 90, d = 12500)[1],
                   ymin = destPoint(p = site_pixels[1,2:3], b = 180, d = 12500)[2],
                   ymax = destPoint(p = site_pixels[1,2:3], b = 0, d = 12500)[2])

# Determining the temperature at the various distances from the coast
```

## Create a visualisation of the sites at the different distances from the coastline. Mapping the study area

```{r}
load("Data_P1/south_africa_coast.RData")
load("Data_P1/africa_coast.RData")
load("Data_P1/sa_provinces_new.RData")
# load("Data_P1/bathy/sa_bathy.RData")
# load("Data_P1/bathy/bathy.RData")
load("Data_P1/site_list_sub.Rdata")
load("Data_P1/site_pixels.RData")
load("Data_P1/MUR.RData")
names(south_africa_coast)[1] <- "lon"

# Manually divide up coastline
wc <- south_africa_coast[291:410,]

# Setting up the theme
theme_set(theme_bw())
limits <- c(12,28) # for colour bar
#breaks <- seq(6, 30, 2) # Create breaks to be used for colour bar

# Define plotting parameters
sa_lats <- c(-37, -27); sa_lons <- c(14, 25)

site_map <- ggplot(data = south_africa_coast, aes(x = lon, y = lat)) + bw_update +
  geom_raster(data = MUR, aes(x = lon, y = lat, fill = temp)) +
   geom_polygon(data = south_africa_coast, aes(x = lon, y = lat, group = group),
                fill = "grey", colour = "grey", size = 0.1, show.legend = FALSE) +
  geom_point(data = site_list_sub, aes(x = lon, y = lat), alpha = 0.8, size = 3) +
  geom_point(data = site_pixels, aes(x = lon, y = lat), colour = "white", shape = 0, alpha = 0.8, size = 2.1) +
  coord_equal(xlim = c(15, 25), ylim = c(-36,-26), expand = 0) +
  # geom_rect(data = bbox, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
  #           alpha = 0.4, colour = "red", size = 0.1, linetype = 1) +
  # scale_x_continuous(limits = sa_lons, expand = c(0, 0), breaks = seq(15, 35, 5)) +
  # scale_y_continuous(limits = sa_lats, expand = c(0, 0), breaks = seq(-35, -30, 5)) +
  scale_fill_viridis(
    option = "magma",
    name = "Temperature (°C)",
    alpha = 0.8) +
  xlab("") + ylab("") +
  # annotate("text", label = "INDIAN\nOCEAN", x = 32.00, y = -35.0,
  #            size = 4, angle = 0, colour = "black") +
    annotate("text", label = "ATLANTIC\nOCEAN", x = 17.00, y = -35.0,
             size =4, angle = 0, colour = "black") +
    annotate("text", label = "Benguela", x = 16.0, y = -31.7,
             size = 4, angle = 302, colour = "black") +
    # annotate("text", label = "Agulhas", x = 31.7, y = -31.7,
    #          size = 5, angle = 50, colour = "black") +
  guides(fill = guide_colourbar()) +
  scale_x_continuous(expand = c(0, 0),
                       labels = scales::unit_format(unit = "°E", sep = "")) +
    scale_y_continuous(expand = c(0, 0),
                       labels = scales::unit_format(unit = "°S", sep = "")) +
  theme(panel.background = element_rect(fill = "ivory", colour = NA),
        panel.border = element_rect(colour = "black", size = 0.5),
        panel.grid.minor = element_line(colour = "NA"),
        panel.grid.major = element_line(colour = "ivory", size = 0.2, linetype = "dotted"),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.key = element_blank(),
        legend.background = element_blank(),
        axis.ticks = element_line(size = 0.5),
        axis.text = element_text(size = 6)) +
    guides(fill = guide_colourbar(barheight = 1.00, barwidth = 10)) +
  theme(panel.background = element_rect(fill = "ivory", colour = NA),
        panel.border = element_rect(colour = "black", size = 0.5),
        panel.grid.minor = element_line(colour = "NA"),
        panel.grid.major = element_line(colour = "ivory", size = 0.2, linetype = "dotted"),
        legend.direction = "horizontal",
        legend.justification = c(1,0),
        legend.position = c(0.65, 0.80),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8),
        legend.key = element_blank(),
        legend.background = element_blank(),
        axis.ticks = element_line(size = 0.5))
site_map

africa_map <- ggplot(africa_coast, aes(x = lon, y = lat)) + 
  theme_bw() + 
  coord_equal() + 
  geom_polygon(aes(group = group), colour = "black", fill = "grey80") + 
  geom_polygon(data = sa_provinces_new, (aes(group = group))) +
  annotate("text", label = "Africa", x = 16.0, y = 15.0, size = 3) + 
  theme(panel.border = element_rect(colour = "black", size = 0.4), 
        plot.background = element_blank(), 
        axis.ticks = element_blank(), 
        axis.text = element_blank(), 
        axis.title = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  coord_map(xlim = c(-20, 53), ylim = c(-36, 38), projection = "mercator") 
africa_map

# More mapping - http://r-nold.blogspot.com/2014/06/creating-inset-map-with-ggplot2.html

pdf("Figures/map_fixed.pdf", width = 10, height = 7, pointsize = 4) # Set PDF dimensions
vp1 <- viewport(x = 0.70, y = 0.58, w = 0.25, h = 0.25) # Africa
vp2 <- viewport(x = 1.0, y = 1.0, w = 1.00, h = 1.00, just = c("right", "top"))  # South Africa
print(site_map, vp = vp2)
print(africa_map, vp = vp1)
dev.off()

# png("Figures/site_map.png", width = 8, height = 5, pointsize = 6)
```

# Wind data

Loading the Wind data. The wind dataset was supplied by the SAWS in .text format. Wind data was provided for the sites closes to the requested site as wind data may not be available for the 6 study sites in this research.  The wind direction was collected every 2 hours and by using the circular function we calcuated the daily wind direction and mean speed. There is a numerically large gap between 360 and 2 where as in degrees its not as large. The circular mean function returns the mean direction of a vector of circular data. https://cran.r-project.org/web/packages/circular/circular.pdf (Pg 130). The circular function creates circular objects around the wind direction. 

```{r}
wind_1 <- read.delim("Data_P1/Wind_data/wind_data.txt(SAWS)/wind1/wind1.txt", na.strings = "", 
                     col.names = c("station_number", "station_name", "date", "hour", "sub", "speed", "dir"))

wind_2 <- read.delim("Data_P1/Wind_data/wind_data.txt(SAWS)/wind2/wind2.txt", na.strings = "",
                     col.names = c("station_number", "station_name", "date", "hour", "sub" ,"speed", "dir"))

wind_3 <- read.delim("Data_P1/Wind_data/wind_data.txt(SAWS)/wind3/wind3.txt", na.strings = "",
                     col.names = c("station_number", "station_name", "date", "hour", "sub" ,"speed", "dir"))

# Slecting the important columns for each of the datasets
wind_fix <- function(df){
wind <- df %>% 
  select(station_name, date, hour, dir, speed) %>%  #column names
  mutate(date = as.Date(as.character(date)),
         hour = as.numeric(as.character(hour)), 
         dir = as.numeric(as.character(dir)),
         speed = as.numeric(as.character(speed)))
}
# RWS: We can see when we force the values to be numeric that there are some non-numeric values in the base data
wind_1 <- wind_fix(df = wind_1)
wind_2 <- wind_fix(df = wind_2)
wind_3 <- wind_fix(df = wind_3)

## Renaming the sites within the wind datasets to match the name of the sites at which seawater temperature was collected
## The wind data was obtained from the SAWS and the wind stations used were the closes stations to which temperature was collected

renaming_sites_1 <- function(df) {
  sites <- df %>%
      # RWS: An alternative way to replace values without having to use multiple ifelse() statements
      mutate(temp_sites = case_when(station_name == "CAPE TOWN TABLE BAY" ~ "Sea Point",
                                    station_name == "CAPE TOWN - ROYAL YACHT CLUB" ~ "Sea Point",
                                    station_name  == "GEELBEK" ~ "Yzerfontein",
                                    station_name  == "CAPE TOWN SLANGKOP" ~ "Kommetjie",
                                    station_name  == "PORT NOLLOTH" ~"Port Nolloth",
                                    station_name  == "LAMBERTSBAAI NORTIER" ~ "Lamberts Bay",
                                    station_name  == "LANGEBAANWEG AWS" ~ "Saldanha Bay"))
  return(sites)
}


wind_sitesmatched_1 <-  renaming_sites_1(df = wind_1)
wind_sitesmatched_2 <-  renaming_sites_1(df = wind_2)
wind_sitesmatched_3 <-  renaming_sites_1(df = wind_3)
wind_data <- rbind(wind_sitesmatched_3,wind_sitesmatched_2,wind_sitesmatched_1)
# save(wind_data, file = "Data_P1/wind_data.RData")

# # RWS: You should never be removing values by specific call like this
#   # Rather you should be able to use some sort of conditional to screen out unwanted values
# wind_sitesmatched_1 <- wind_sitesmatched_1[-c(121352, 121353, 379892, 379893, 609324, 609325, 843506, 843507, 1014585), ]
# renaming_sites_2 <- function(df) {
#   sites <- df %>%
#     mutate(temp_sites = ifelse(station_name %in% c("ROBBENEILAND"), "Koeberg Basin",        
#                            ifelse(station_name %in% c("GEELBEK"), "Yzerfontein",
#                                 ifelse(station_name %in% c("DASSEN ISLAND"), "Dassen Island",
#                                        ifelse(station_name %in% c("ATLANTIS"), "Koeberg Basin","Error")))))
#   return(sites)
# }
# 
# wind_sitesmatched_2 <-  renaming_sites_2(df = wind_2)
# wind_sitesmatched_2 <- wind_sitesmatched_2[-c(228372, 228373, 313441, 313442, 364881, 364882, 557392), ] 
# renaming_sites_3 <- function(df) {
#   sites <- df %>%
#     mutate(temp_sites = ifelse(station_name %in% c("CAPE TOWN SLANGKOP"), "Kommetjie",  
#                            ifelse(station_name %in% c("CAPE TOWN - ROYAL YACHT CLUB"), "Sea Point",
#                            ifelse(station_name %in% c("CAPE TOWN TABLE BAY"), "Sea Point","Error"))))
#   return(sites)
# }
# 
# wind_sitesmatched_3 <-  renaming_sites_3(df = wind_3)
# wind_sitesmatched_3 <- wind_sitesmatched_3[-c(119317, 119318, 196551, 196552, 346759), ] 
### CAPE TOWN SLANGKOP may be used for Kommetjie and for Houtbay
# wind_3_HoutBay <- wind_3 %>% 
#   filter(station_name == "CAPE TOWN SLANGKOP") %>% 
#   mutate(temp_sites = ifelse(station_name %in% c("CAPE TOWN SLANGKOP"), "Hout Bay","Error"))
# wind_data <- rbind(wind_3_HoutBay,wind_sitesmatched_3,wind_sitesmatched_2,wind_sitesmatched_1)
# wind_data <- wind_data %>% 
#   na.omit()
# 
# wind_data <- wind_data %>% 
#   # mutate(date = as.Date(date)) %>%  
#   group_by(date, hour, temp_sites) 
# 
# # write.csv(wind_data, file = "Data_P1/wind_data.csv", row.names = T)
# # save(wind_data, file = "Data_P1/wind_data.RData")

# load("Data_P1/insitu_wind.RData")
# 
# test1 <- insitu_wind %>% 
#   mutate(lat = case_when(site == "Port Nolloth" ~ "-29.25241",
#                                     site == "Saldanha Bay" ~ "-33.01054",
#                                     site  == "Yzerfontein" ~ "-33.36068",
#                                     site  == "Kommetjie" ~ "-34.13667",
#                                     site  == "Lamberts Bay" ~ "-32.09185",
#                                     site  == "Sea Point" ~ "-33.91847"))
# 
# test <- test1 %>% 
#   mutate(lon = case_when(site == "Port Nolloth" ~ "16.86710",
#                                     site == "Saldanha Bay" ~ "17.95063",
#                                     site  == "Yzerfontein" ~ "18.15731",
#                                     site  == "Kommetjie" ~ "18.32674",
#                                     site  == "Lamberts Bay" ~ "18.30262",
#                                     site  == "Sea Point" ~ "18.38217"))
# 
# test_final <- test %>% 
#   select(date,lat,lon,dir_circ, mean_speed) %>% 
#   dplyr::rename(speed = mean_speed) %>% 
#   dplyr::rename(dir = dir_circ)

# Loading the wind data
library(tidyverse)
library(circular)

# wind_data <- read_csv("wind_data.csv", col_types = cols(X1 = col_number(), date = col_character(), dir = col_number(), hour = col_number(),  speed = col_number())) # Dataset too large for Github but better data at line 638

# wind_data <- read_csv("Data_P1/wind_data.csv")
selected_sites <- c("Port Nolloth", "Lamberts Bay", "Sea Point", "Saldanha Bay", "Yzerfontein", "Kommetjie") 

wind_daily <- wind_data %>%
  # ungroup() %>%
  # mutate(date = as.Date(date))%>%
  dplyr::group_by(temp_sites, date) %>%
  filter(temp_sites %in% selected_sites) %>% 
  dplyr::summarise(dir_circ = round(mean.circular(circular(dir, units = "degrees")),2),
                   mean_speed = round(mean(speed),2)) 


# save(wind_daily, file = "Data_P1/wind_daily.RData")
# # Loading in the daily wind data

# Loading the subsetted wind data created from the text files above 
load("Data_P1/wind_daily.RData") 
```
 
Matching wind data to the in situ collected data. This is done in order to plot the wind patterns for the same date at which temperature was collected. The satellite obtained SST data is also matched by date to the in situ temperature data and so the dates correspond. 

```{r}
# load("Data_P1/SACTN_overlap.RData")
# load("Data_P1/wind_daily.RData")
# wind_daily <- wind_daily%>% 
#   dplyr::rename(site = temp_sites) # Renaming to match the `match_func` previously created
# 
# insitu_wind <- match_func(df = wind_daily)  # Using `match_func`
# 
# insitu_wind <- insitu_wind %>% 
#   filter(year(date) %in% seq(2010, 2014)) # The years 2010-2014 is the years of interest and the years for which wavelets are/will be created.
  
# save(insitu_wind, file = "Data_P1/insitu_wind.RData")
```

# Plotting the wind data - windrose diagrams
  # Here I produce a wind rose diagram showing wind action or wind patterns during the upwelling period

```{r}
# Loading in the matched wind data
load("Data_P1/insitu_wind.RData")

insitu_wind <- insitu_wind %>% 
  drop_na()

wave_daily_renamed <- insitu_wind %>% 
  dplyr::rename(spd = mean_speed) %>%
  dplyr::rename(dir = dir_circ) 
source("functions/wind.rose.R")
p.wr2 <- plot.windrose(data = wave_daily_renamed,
              spd = "spd",
              dir = "dir")
p.wr3 <- p.wr2 + facet_wrap(.~ site, ncol = 2, nrow = "") +
  theme(strip.text.x = element_text(size = 25))
p.wr3 # RWS: You'll want to remove the NA part in the figure output

#########################
library(openair)
print(
with(insitu_wind,
     windRose(data_frame(ws=mean_speed, wd=dir_circ, 
                         date=date, station=factor(site)),

              paddle=FALSE, type="station", width=2))
)
# png("Figures/wind.png", width = 8, height = 5, pointsize = 6)
?windRose

# insitu_wind_2 <- insitu_wind %>% 
#   filter(site == "Port Nolloth")
# 
# insitu_wind_3 <- insitu_wind %>% 
#   filter(site == "Lamberts Bay")
# 
# plotPN <- plot(as.factor(format(insitu_wind_2$date, "%Y-%m")), insitu_wind_2$insitu_temp, col = "lightpink")
# plotLB <- plot(as.factor(format(insitu_wind_3$date, "%Y-%m")), insitu_wind_3$insitu_temp, col = "lightpink")
#        
# ?plot
```

## Chlorophyll-a data

Extract the chlorophyll a netCDF files and convert it to CSV. The chlorophylla data were obtained from MODIS Aqua. The aim of working with these chlorophyll a data is to examine how the chlorophyll a concentration varies with upwelling. This function convert chlorophyll netCDF datasets to a single CSV dataset.

```{r}
# MODIS_chlor.dir <- "/home/amieroh/Documents/Data/Datasets/Chlorophyll_a"
# MODIS_chlor.csv.dir <- "/home/amieroh/Documents/Data/Datasets"

# region <- "BC" # Benguela Current
# 
# coords <- c(-35, -20, 10, 20) # this is the BC
# 
# ncList <- list.files(path = MODIS_chlor.dir, pattern = "*.nc", full.names = TRUE, include.dirs = TRUE)
# strt.date <- str_sub(basename(ncList[1]), start = 2, end = 8)
# end.date <- str_sub(basename(ncList[length(ncList)]), start = 2, end = 8)
# nc.init <- nc_open(ncList[1])
# LatIdx <- which(nc.init$dim$lat$vals > coords[1] & nc.init$dim$lat$vals < coords[2])
# LonIdx <- which(nc.init$dim$lon$vals > coords[3] & nc.init$dim$lon$vals < coords[4])
# nc_close(nc.init)
# 
# 
# ncFun <- function(nc.file = nc.files, csv.dir = csv.dir) {
# nc <- nc_open(nc.file)
#   instrument <- ncatt_get(nc, 0, "instrument")$value
#   platform <- ncatt_get(nc, 0, "platform")$value
#   product_name <- ncatt_get(nc, 0, "product_name")$value
#   fNameStem <- substr(product_name, 17, 38)
#   timeStamp <- substr(product_name, 2, 8)
#   origin <- paste0(substr(timeStamp, 1, 4), "-01-01")
#   date <- as.Date(as.numeric(substr(timeStamp, 5, 7)), origin)
#   chl <- round(ncvar_get(nc,
#                    varid = "chlor_a",
#                    start = c(LonIdx[1], LatIdx[1]),
#                    count = c(length(LonIdx), length(LatIdx))),
#                3)
#   dimnames(chl) <- list(lon = nc$dim$lon$vals[LonIdx],
#                         lat =  nc$dim$lat$vals[LatIdx])
#   nc_close(nc)
#   chl <-
#     as.data.table(melt(chl, value.name = "chl"), row.names = NULL) %>%
#     mutate(t = date) %>%
#     na.omit()
#   fwrite(chl,
#          file = paste(csv.dir, "/", region, "-", instrument, ".",platform, ".",
#                       fNameStem, "-", strt.date, "-", end.date, ".csv", sep = ""),
#          append = TRUE, col.names = FALSE)
#   rm(chl)
# }
# 
# llply(ncList, ncFun, csv.dir = MODIS_chlor.csv.dir, .parallel = TRUE)

# MODIS_Chloro <- "~/Documents/Masters_2019/MastersProject/Data"
# MODIS_Chloro <- fread(paste0(MODIS_Chloro, "/BC-M ODIS.Aqua.L3m_8D_CHL_chlor_a_9km-2002185-2018345.csv"),
#             col.names = c("lon", "lat", "chloro", "date"))

# save(MODIS_Chloro, file = "Data/MODIS_Chloro.RData")
```

## Setting up the chlorophylla dataset

```{r}

# Loading the data
# load("Data_P1/MODIS_Chloro.RData") # Extracted/Raw chlorophyll data
# load("Data_P1/site_list_sub.Rdata") # Site list of all the sites along the west coast
# 
# # Visualisation
# chloro_plot <- MODIS_Chloro %>%
#   filter(date == min(date)) %>%
#   ggplot(aes(x = lon, y = lat)) +
#   geom_raster(aes(fill = chloro))
# 
# unique_pixel <- MODIS_Chloro %>% 
#   select(lon, lat) %>% 
#   unique()
# 
# match_index <- knnx.index(data = as.matrix(unique_pixel[,1:2]),
#                           query = as.matrix(site_list_sub[,5:6]), k = 1)
# 
# # Matching the chlorophylla-a lats and lons to the study sites
# pixel_match <- unique_pixel[match_index,] %>%
#   unite(col = combi, lon, lat, sep = "/", remove = F) %>%
#   mutate(site = site_list_sub$site)
# 
# chloro_match <- MODIS_Chloro %>%
#   unite(col = combi, lon, lat, sep = "/", remove = F) %>%
#   filter(combi %in% pixel_match$combi)
# 
# chloro_match %>%
#   filter(date == max(date)) %>%
#   ggplot(aes(x = lon, y = lat)) +
#   geom_raster(aes(fill = chloro))
# 
# chloro_sites <- chloro_match %>%
#   left_join(pixel_match, by = c("combi", "lon", "lat")) %>% 
#   dplyr::mutate(date = as.Date(date))
# # save(chloro_sites, file = "Data_P1/chloro_sites.RData")
# 
# # Visualisation
# load("Data_P1/chloro_sites.RData")
# Chloro_plot_complete <- ggplot(chloro_sites, aes(x = date, y = chloro)) +
#   geom_line() +
#   facet_wrap(~site, ncol = 1)
# Chloro_plot_complete
# 
# # Study period from 2010 - 2014
# chloro_data <- chloro_sites %>% 
#   filter(year(date) %in% seq(2010, 2014))
# # save(chloro_data, file = "Data_P1/chloro_data.RData")
# 
# # Plotting only years 2014-2015
# load("Data_P1/chloro_data.RData")
# Chloro_plot_filtered <- ggplot(chloro_data, aes(x = date, y = chloro)) +
#   geom_line() +
#   facet_wrap(~site, ncol = 1)
# Chloro_plot_filtered

# Creating daily temperatures
load("Data_P1/chloro_data.RData") # Loading in the chlorophyll-a data

daily_chloro <- chloro_data %>%
  # dplyr::mutate(date = as.Date(date)) %>% 
  dplyr::group_by(combi, lon, lat, date) %>%
  dplyr::summarise(chloro = mean(chloro, na.rm = TRUE)) %>%
  dplyr::group_by(combi, lon, lat) %>% 
  drop_na() %>% 
  tidyr::nest() %>%
  dplyr::mutate(clims = purrr::map(data, ts2clm, x = date, y = chloro,
                     climatologyPeriod = c("2010-02-11", "2014-12-20"),
                     maxPadLength = 8)) %>% # Adjust maxPadLength = X for longer interpolation
  dplyr::select(-data) %>%
  tidyr::unnest() %>%
  select(-doy, -seas, -thresh)
```

First I calculate the distance between the sites along the wc using the deg2rad function which transforms degrees to radians: Transforms between angles in degrees and radians. Thereafter I run a three way ANOVA. This was primarily done to test whether a significant difference in temperature exist between sites on a seasonal, yearly bases. Here the distance between the sites could also play a role. But distance is mainly used when compaing the intensity and duration of an upwelling event given the distance between the sites and its location (location: at an upwelling centre or further away)

```{r}
load("Data_P1/sa_coast.Rdata")
load("Data_P1/site_list_sub.Rdata")
load("Data_P1/SACTN_fyears.RData")
load("Data_P1/MUR_fyears.RData")
load("Data_P1/OISST_fyears.RData")
load("Data_P1/G1SST_fyears.RData")
load("Data_P1/K10_fyears.RData")
SACTN_fyears <- SACTN_fyears %>% 
  dplyr::rename(temp = insitu_temp)

options(scipen=999) # Forces R to not use exponential notation
sa_coast_prep <- sa_coast %>% 
  mutate(site = 1:nrow(.),
         X = deg2rad(X),
         Y = deg2rad(Y)) %>% 
  select(site, X, Y)

sa_coast_dist <- as.data.frame(round(PairsDists(sa_coast_prep), 2)) %>% 
  mutate(lon = sa_coast$X,
         lat = sa_coast$Y) %>% 
  dplyr::rename(dist = V1) %>%
  select(lon, lat, dist) %>% 
  mutate(cum_dist = cumsum(dist)) %>% 
  mutate(dist = lag(dist),
         cum_dist = lag(cum_dist))

# Calculating the distances between sites.
# This may be used to show how upwelling temperature varies between sites based on its location, i.e. closer 
# to the upwelling centre and further from the upwelling centre

SACTN_site_dis <- function(df) {
  SACTN_dis <- data.frame()
  df2 <- df %>%
    select(-length) %>%
    droplevels()
  for (i in 1:length(levels(df2$index))) {  
    # for (i in 1:10) {
    SACTN_df_1 <- filter(df2, index == levels(index)[i])
       # Find the cumulative distance of site 1 along the coast
    site_dist_1 <- site_list_sub %>% 
      filter(index == as.character(SACTN_df_1$index)[1])
    site_dist_1 <- knnx.index(data = as.matrix(sa_coast_dist[,1:2]),
                              query = as.matrix(site_dist_1[,5:6]), k = 1)
    site_dist_1 <- sa_coast_dist$cum_dist[site_dist_1]
    
    for (j in 1:length(levels(df2$index))) {
      # for(j in 1:10) {
      if (i == j) {
        next
      }
      if (j < i) {
        next
      }
      SACTN_df_2 <- filter(df2, index == levels(index)[j])
      
      # Find the cumulative distance of site 2 along the coast
      site_dist_2 <- site_list_sub %>% 
        filter(index == as.character(SACTN_df_2$index)[1])
      site_dist_2 <- knnx.index(data = as.matrix(sa_coast_dist[,1:2]),
                                query = as.matrix(site_dist_2[,5:6]), k = 1)
      site_dist_2 <- sa_coast_dist$cum_dist[site_dist_2]
      
      # # The distance between the two sites
      site_dist_3 <- round(abs(site_dist_1-site_dist_2), 0)

      SACTN_df_3 <- left_join(SACTN_df_1, SACTN_df_2, by = "date") %>%
        na.trim() %>% 
      select(date, index.x, temp.x, index.y, temp.y) %>%
        dplyr::rename(index_1 = index.x,
          temp_1 = temp.x,
          index_2 = index.y,
          temp_2 = temp.y) %>% 
        mutate(index_dist = site_dist_3)
      SACTN_dis <- rbind(SACTN_dis, SACTN_df_3)
    }
  }
  return(SACTN_dis)
}
SACTN_site_dist <- SACTN_site_dis(df = SACTN_fyears)

# Adding seasonal column

SACTN_monthly <- function(df) {
  SACTN_split_monthly <- df %>%
  mutate(month = month(date, abbr = T, label = T),
         year = year(date)) %>%
  group_by(index, month, year) %>%
    mutate(season = ifelse(month %in% c("Jan", "Feb", "Mar"), "Summer",       
                           ifelse(month %in% c("Apr", "May", "Jun"), "Autumn",
                                ifelse(month %in% c("Jul", "Aug", "Sep"), "Winter",
                                       ifelse(month %in% c("Oct", "Nov", "Dec"), "Spring","Error")))))
  return(SACTN_split_monthly)
}

# SACTN_season <- SACTN_monthly(df = SACTN_fyears)
# MUR_fyears_season <- SACTN_monthly(df = MUR_fyears)
# OISST_fyears_season <- SACTN_monthly(df = OISST_fyears)
# G1SST_fyears_season <- SACTN_monthly(df = G1SST_fyears)
# K10_fyears_season <- SACTN_monthly(df = K10_fyears)

# save(SACTN_season, file = "SACTN_season.RData")
# save(MUR_fyears_season, file = "MUR_fyears_season.RData")
# save(OISST_fyears_season, file = "OISST_fyears_season.RData")
# save(G1SST_fyears_season, file = "G1SST_fyears_season.RData")
# save(K10_fyears_season, file = "K10_fyears_season.RData")

load("Data_P1/SACTN_season.RData")
load("Data_P1/MUR_fyears_season.RData")
load("Data_P1/OISST_fyears_season.RData")
load("Data_P1/G1SST_fyears_season.RData")
load("Data_P1/K10_fyears_season.RData")

# ANOVA analyses
anova_func <- function(df){
  sites_aov <- aov(temp ~ site * year * season, data = df)
return(sites_aov)
}

SACTN_season <- SACTN_season %>% 
  dplyr::rename(temp = insitu_temp)

SACTN_season_func <- anova_func(df = SACTN_season)
summary(SACTN_season_func)
MUR_season_func <- anova_func(df = MUR_fyears_season)
summary(MUR_season_func)
OISST_season_func <- anova_func(df = OISST_fyears_season)
summary(OISST_season_func)
G1SST_season_func <- anova_func(df = G1SST_fyears_season)
summary(G1SST_season_func)
K10_season_func <- anova_func(df = K10_fyears_season)
summary(K10_season_func)

# Shows a significant different in temperatures between sites for each of the years and between seasons

#    ? This is for all temperatures collected. not only temperatures collected during an upwelling event
#    ? So now I need to find a way to restrict temperatures to only the periods where upwelling occured
#    ? Can use the heatwaveR package to identify the count, intensity and duration but for this I require to know what the upwelling threshold is
#     MHW: threshold- 90th percentile, MCS: Threshold - 10th percentile
```

# Here I want to test using generalised linear hypotheses if there is a difference in the intensity of upwellling events between the insitu and       satellite data.
# Do the in situ and satelllite derived data yield the same number of events. First I add a seasonal column to test seasonal variation between 
library(multcomp) # for generalized linear hypothesis test (glht)

```{r}

```

Determining the R2 value between *in situ* and remotely sensed SST

```{r}
# Loading the *in situ* and Remotely sensed SST

load("Data_P1/SACTN_fyears.RData")
load("Data_P1/OISST_fyears.RData")

SACTN_fyears <- SACTN_fyears %>% 
  dplyr::rename(temp = insitu_temp)

R2 <- data.frame()
for(i in 1:length(levels(SACTN_fyears$site))) {
  x <- subset(SACTN_fyears, site == levels(SACTN_fyears$site)[i])
  y <- subset(df, site == levels(df$site)[i])
  x <- x[x$date %in% y$date,]
  y <- y[y$date %in% x$date,]
  z <- data.frame(site = as.character(x$site[1]), R2 = coef(lm(y$temp~x$temp))[2])
  R2 <- rbind(R2, z)
}
```

# Upwelling index
## Determining upwelling index from wind data (WindGuru and SAWS)
## Index Equation from Fielding & Davis 1989 paper

```{r}
load("Data_P1/insitu_wind.RData")
load("Data_P1/SACTN_fyears.RData")
load("Data_P1/MUR_fyears.RData")
load("Data_P1/OISST_fyears.RData")
load("Data_P1/G1SST_fyears.RData")
load("Data_P1/K10_fyears.RData")

# UPWELLING INDEX EQUATION  - FIELDING & DAVIS 1989
# Index = Wind_speed*cos(wind_direction) - 160) [*160 refers to the angle (degrees) of the coast]

#data wrangling - TEMPERATURE
SACTN_fyears_UI <- SACTN_fyears %>% 
  dplyr::rename(temp = insitu_temp) %>%
  group_by(site) %>%
  select("date", "temp") 

wind_UI <- insitu_wind %>%
  group_by(site) %>%
  mutate(ui.saws = mean_speed * (cos(dir_circ - 160))) %>% 
  drop_na()

index <- wind_UI %>%
  group_by(site) %>% 
  select("site", "date","ui.saws") %>% 
  left_join(SACTN_fyears_UI, by = c("date", "site")) %>% 
  mutate(saws.condition = ifelse(ui.saws > 0, "upwelling", "downwelling"))

#Plotting the data
#SAWS data
ggplot(index, aes(x= date, y=ui.saws)) +
  geom_area(aes(fill=saws.condition)) +
  facet_wrap(~site) +
  geom_hline(yintercept=0)

# Seperating sites
index_SP <- index %>% 
  filter(site == "Sea Point") %>% 
  slice(-(c(34:70,435:632,686,1704)))

index_KOM <- index %>% 
  filter(site == "Kommetjie")

index_PN <- index %>% 
  filter(site == "Port Nolloth")

index_YZ <- index %>% 
  filter(site == "Yzerfontein")

index_LB <- index %>% 
  filter(site == "Lamberts Bay")

index_SB <- index %>% 
  filter(site == "Saldanha Bay")

# Visualisation
#Plotting the data
#SAWS data

upwell_plot <- function(df){
  plot <- df %>% 
  ggplot(aes(x= date, y=ui.saws)) +
  geom_area(aes(fill=saws.condition)) +
  geom_hline(yintercept=0)
}

upwell_SP <- upwell_plot(df = index_SP) 
upwell_KOM <- upwell_plot(df = index_KOM) 
upwell_PN <- upwell_plot(df = index_PN) 
upwell_YZ <- upwell_plot(df = index_YZ) 
upwell_SB <- upwell_plot(df = index_SB) 
upwell_LB <- upwell_plot(df = index_LB) 


upwell_int <- function(df){
  interp <- approx(df$date, df$ui.saws, n=100000)
}
upwell_int_SP <- upwell_int(df = index_SP) 
upwell_int_KOM <- upwell_int(df = index_KOM) 
upwell_int_PN <- upwell_int(df = index_PN) 
upwell_int_YZ <- upwell_int(df = index_YZ) 
upwell_int_LB <- upwell_int(df = index_LB) 
upwell_int_SB<- upwell_int(df = index_SB) 

interp <- function(df){
  interp <- approx(df$date, df$ui.saws, n=100000)
}
interp_SP <- interp(df = index_SP) 
interp_KOM <- interp(df = index_KOM) 
interp_PN <- interp(df = index_PN) 
interp_YZ <- interp(df = index_YZ) 
interp_LB <- interp(df = index_LB) 
interp_SB<- interp(df = index_SB) 

interp2 <- function(df){
  interp2 <- approx(df$date, df$ui.saws, n=100000)
}

interp2_SP <- interp2(df = index_SP) 
interp2_KOM <- interp2(df = index_KOM) 
interp2_PN <- interp2(df = index_PN) 
interp2_YZ <- interp2(df = index_YZ) 
interp2_LB <- interp2(df = index_LB) 
interp2_SB<- interp2(df = index_SB) 

# Sea Point
UIi_SP <- data.frame(Day=interp_SP$x, Index=interp_SP$y, Temp = interp2_SP$y)
UIi_SP$saws_condition[UIi_SP$Index >= 0] <- "upwelling"
UIi_SP$saws_condition[UIi_SP$Index < 0] <- "downwelling"

index_plot_SP <- ggplot(UIi_SP, aes(x=Day, y=Index)) +
  geom_area(aes(fill=saws_condition)) +
  geom_hline(yintercept=0) +
  theme_bw() +
  # annotate("text", x = 300, y = -12.5, label = "SAWS Data") +
  #geom_vline(xintercept = c(116, 117, 133, 134, 244, 291), lty = 2, lwd = 1) +
  scale_fill_manual(values=c("salmon", "steelblue")) +
  scale_x_continuous(expand=c(0, 0)) +
  scale_y_reverse() +
  labs(y= "Upwelling Index") +
  guides(fill=guide_legend(title="Condition")) +
  ggtitle("Sea Point")
index_plot_SP

# Kom
UIi_KOM <- data.frame(Day=interp_KOM$x, Index=interp_KOM$y, Temp = interp2_KOM$y)
UIi_KOM$saws_condition[UIi_KOM$Index >= 0] <- "upwelling"
UIi_KOM$saws_condition[UIi_KOM$Index < 0] <- "downwelling"

index_plot_KOM <- ggplot(UIi_KOM, aes(x=Day, y=Index)) +
  geom_area(aes(fill=saws_condition)) +
  geom_hline(yintercept=0) +
  theme_bw() +
  # annotate("text", x = 300, y = -12.5, label = "SAWS Data") +
  #geom_vline(xintercept = c(116, 117, 133, 134, 244, 291), lty = 2, lwd = 1) +
  scale_fill_manual(values=c("salmon", "steelblue")) +
  scale_x_continuous(expand=c(0, 0)) +
  scale_y_reverse() +
  labs(y= "Upwelling Index") +
  guides(fill=guide_legend(title="Condition")) +
  ggtitle("Kommetjie")
index_plot_KOM

# Port Nolloth
UIi_PN <- data.frame(Day=interp_PN$x, Index=interp_PN$y, Temp = interp2_PN$y)
UIi_PN$saws_condition[UIi_PN$Index >= 0] <- "upwelling"
UIi_PN$saws_condition[UIi_PN$Index < 0] <- "downwelling"

index_plot_PN<- ggplot(UIi_PN, aes(x=Day, y=Index)) +
  geom_area(aes(fill=saws_condition)) +
  geom_hline(yintercept=0) +
  theme_bw() +
  # annotate("text", x = 300, y = -12.5, label = "SAWS Data") +
  #geom_vline(xintercept = c(116, 117, 133, 134, 244, 291), lty = 2, lwd = 1) +
  scale_fill_manual(values=c("salmon", "steelblue")) +
  scale_x_continuous(expand=c(0, 0)) +
  scale_y_reverse() +
  labs(y= "Upwelling Index") +
  guides(fill=guide_legend(title="Condition")) +
  ggtitle("Port Nolloth")
index_plot_PN

# Yzerfontein
UIi_YZ <- data.frame(Day=interp_YZ$x, Index=interp_YZ$y, Temp = interp2_YZ$y)
UIi_YZ$saws_condition[UIi_YZ$Index >= 0] <- "upwelling"
UIi_YZ$saws_condition[UIi_YZ$Index < 0] <- "downwelling"

index_plot_YZ<- ggplot(UIi_YZ, aes(x=Day, y=Index)) +
  geom_area(aes(fill=saws_condition)) +
  geom_hline(yintercept=0) +
  theme_bw() +
  # annotate("text", x = 300, y = -12.5, label = "SAWS Data") +
  #geom_vline(xintercept = c(116, 117, 133, 134, 244, 291), lty = 2, lwd = 1) +
  scale_fill_manual(values=c("salmon", "steelblue")) +
  scale_x_continuous(expand=c(0, 0)) +
  scale_y_reverse() +
  labs(y= "Upwelling Index") +
  guides(fill=guide_legend(title="Condition")) +
  ggtitle("Yzerfontein")
index_plot_YZ

# Lamberts Bay
UIi_LB <- data.frame(Day=interp_LB$x, Index=interp_LB$y, Temp = interp2_LB$y)
UIi_LB$saws_condition[UIi_LB$Index >= 0] <- "upwelling"
UIi_LB$saws_condition[UIi_LB$Index < 0] <- "downwelling"

index_plot_LB<- ggplot(UIi_LB, aes(x=Day, y=Index)) +
  geom_area(aes(fill=saws_condition)) +
  geom_hline(yintercept=0) +
  theme_bw() +
  # annotate("text", x = 300, y = -12.5, label = "SAWS Data") +
  #geom_vline(xintercept = c(116, 117, 133, 134, 244, 291), lty = 2, lwd = 1) +
  scale_fill_manual(values=c("salmon", "steelblue")) +
  scale_x_continuous(expand=c(0, 0)) +
  scale_y_reverse() +
  labs(y= "Upwelling Index") +
  guides(fill=guide_legend(title="Condition")) +
  ggtitle("Lamberts Bay")
index_plot_LB

# Saldanha Bay
UIi_SB <- data.frame(Day=interp_SB$x, Index=interp_SB$y, Temp = interp2_SB$y)
UIi_SB$saws_condition[UIi_SB$Index >= 0] <- "upwelling"
UIi_SB$saws_condition[UIi_SB$Index < 0] <- "downwelling"

index_plot_SB<- ggplot(UIi_SB, aes(x=Day, y=Index)) +
  geom_area(aes(fill=saws_condition)) +
  geom_hline(yintercept=0) +
  theme_bw() +
  # annotate("text", x = 300, y = -12.5, label = "SAWS Data") +
  #geom_vline(xintercept = c(116, 117, 133, 134, 244, 291), lty = 2, lwd = 1) +
  scale_fill_manual(values=c("salmon", "steelblue")) +
  scale_x_continuous(expand=c(0, 0)) +
  scale_y_reverse() +
  labs(y= "Upwelling Index") +
  guides(fill=guide_legend(title="Condition")) +
  ggtitle("Saldanha Bay")
index_plot_SB

upwelling_index <- ggarrange(index_plot_SP, index_plot_KOM, index_plot_PN,
          index_plot_YZ,index_plot_LB, index_plot_SB, ncol = 2, nrow = 3)
```

Calculating the temperature anomalies. This will be plotted on the same graph as the upwelling indeces. This allows for an observation on the relationship or patterns that exist as a result of temperature changes and he upwelling and downwelling conditions.

```{r}

```

### EOF's

```{r} 
PCA_1 <- rda(tester)
summary(PCA)

# Proportion of variation explained
# Values to be found opon running the code

PCA <- cbind(scores(PCA_1, choices = c(1:4), display = "sites"))
PCA_spe <- cbind(scores(PCA_1, choices = c(1:4), display = "species"))

test1 <- ggplot(PCA, aes(x = lon, y = lat)) +
  geom_raster(aes(fill = PC1)) +
  geom_polygon(data = PC1, aes(long, lat, group = group),
               fill = NA, colour = "blue", size = 0.3) +
  geom_polygon(data = velocity, aes(long, lat, group = group),
               fill = NA, colour = "green", size = 0.3)+ 
         fill = guide_colourbar(title = "PC1")

test2 <- ggplot(PCA, aes(x = lon, y = lat)) +
  geom_raster(aes(fill = PC2)) +
  geom_polygon(data = PC1, aes(long, lat, group = group),
               fill = NA, colour = "blue", size = 0.3) +
  geom_polygon(data = velocity, aes(long, lat, group = group),
               fill = NA, colour = "green", size = 0.3)+ 
         fill = guide_colourbar(title = "PC2")

test3 <- ggplot(PCA, aes(x = lon, y = lat)) +
  geom_raster(aes(fill = PC2)) +
  geom_polygon(data = PC1, aes(long, lat, group = group),
               fill = NA, colour = "blue", size = 0.3) +
  geom_polygon(data = velocity, aes(long, lat, group = group),
               fill = NA, colour = "green", size = 0.3)+ 
         fill = guide_colourbar(title = "PC3")

test4 <- ggplot(PCA, aes(x = lon, y = lat)) +
  geom_raster(aes(fill = PC1)) +
  geom_polygon(data = PC1, aes(long, lat, group = group),
               fill = NA, colour = "blue", size = 0.3) +
  geom_polygon(data = velocity, aes(long, lat, group = group),
               fill = NA, colour = "green", size = 0.3)+ 
         fill = guide_colourbar(title = "PC4")

pc1_combined <- ggarrange( test1, test2, test3, test4)

```

In particular, trends will be observed to be different at ocean and coastal locations and we hypothesize that those differences are due to changes in upwelling intensity.













































